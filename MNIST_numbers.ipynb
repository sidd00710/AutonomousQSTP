{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w2pwVRmTR-o"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl9HsDSRTcmp"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST('trainset', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST('testset', train = False,download=True,transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset,batch_size = 100,shuffle = True,num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(testset,batch_size = 100,shuffle = False,num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzCwxKcVegm7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channels=1,\n",
        "                                                out_channels=5,\n",
        "                                                kernel_size=3,\n",
        "                                                stride=1,\n",
        "                                                padding=1), \n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=5,\n",
        "                                                out_channels=10,\n",
        "                                                kernel_size=3,\n",
        "                                                stride=1,\n",
        "                                                padding=1), \n",
        "                                      nn.MaxPool2d(2, 2),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.BatchNorm2d(10),\n",
        "                                      nn.Conv2d(in_channels=10,\n",
        "                                                out_channels=20,\n",
        "                                                kernel_size=3,\n",
        "                                                stride=1,\n",
        "                                                padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.BatchNorm2d(20),\n",
        "                                      nn.Conv2d(in_channels=20,\n",
        "                                                out_channels=40,\n",
        "                                                kernel_size=3,\n",
        "                                                stride=1,\n",
        "                                                padding=1),\n",
        "                                      nn.MaxPool2d(2, 2),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.BatchNorm2d(40))\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(7 * 7 * 40, 200),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(200, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(500, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)       \n",
        "        x = x.view(-1, 7 * 7 * 40)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWjn9e4-egsV"
      },
      "source": [
        "model = Net()\n",
        "losscalc=nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr = 3e-4,\n",
        "                       weight_decay= 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdXJCv-peps6",
        "outputId": "417b0cd2-9766-4577-c047-a555de9987a2"
      },
      "source": [
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "for epoch in range(10):\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        train, labels = data       \n",
        "        optimizer.zero_grad()      \n",
        "        outputs = model(train)      \n",
        "        loss = losscalc(outputs, labels)       \n",
        "        loss.backward()       \n",
        "        optimizer.step()\n",
        "        count += 1\n",
        "        \n",
        "        if count % 600 == 0:        \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for i, data in enumerate(test_loader, 0):\n",
        "                test, labels = data\n",
        "                outputs = model(test)\n",
        "                predicted = torch.max(outputs.data, 1)[1] \n",
        "                total += len(labels)               \n",
        "                correct += (predicted == labels).sum()           \n",
        "            accuracy = 100 * correct / float(total)\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "        \n",
        "            print('Epoch: {}  Loss: {}  Accuracy: {} %'.format(count/600, loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1.0  Loss: 0.027901282534003258  Accuracy: 97.70999908447266 %\n",
            "Epoch: 2.0  Loss: 0.0706169605255127  Accuracy: 98.33999633789062 %\n",
            "Epoch: 3.0  Loss: 0.010883302427828312  Accuracy: 98.51000213623047 %\n",
            "Epoch: 4.0  Loss: 0.17128999531269073  Accuracy: 98.55000305175781 %\n",
            "Epoch: 5.0  Loss: 0.008609485812485218  Accuracy: 98.69000244140625 %\n",
            "Epoch: 6.0  Loss: 0.022639267146587372  Accuracy: 98.72000122070312 %\n",
            "Epoch: 7.0  Loss: 0.06403082609176636  Accuracy: 98.62000274658203 %\n",
            "Epoch: 8.0  Loss: 0.011927729472517967  Accuracy: 98.70999908447266 %\n",
            "Epoch: 9.0  Loss: 0.008247327990829945  Accuracy: 98.7300033569336 %\n",
            "Epoch: 10.0  Loss: 0.01265181228518486  Accuracy: 98.80999755859375 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrRKqJw6pdA3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
